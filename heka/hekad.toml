# Heka dashboard for internal metrics and time series graphs
[Dashboard]
type = "DashboardOutput"
address = ":4352"
ticker_interval = 15

[tcp:2003]
type = "TcpInput"
splitter = "TokenSplitter"
decoder = "cf-collector-graphite-decoder"
address = ":2003"

#  nifty go regex tester https://regoio.herokuapp.com/
[cf-collector-graphite-decoder]
type = "MultiDecoder"
subs = ['cf-collector-regex', 'StatsToFieldsDecoder']
cascade_strategy = "all"
log_sub_errors = true

[cf-collector-regex]
type = "PayloadRegexDecoder"
# cf-np.DEA.0.10-1-2-3.available_memory_ratio 1.0 1428091803
#match_regex = '^(?P<Env>[^.]+)[.](?P<Job>[^.]+)[.](?P<Index>\d+)[.](?P<IP>[^.]+)[.](?P<Metric>\S+) (?P<Value>\S+) (?P<Timestamp>\d+)\s*$'
match_regex = '^(?P<Env>[^.]+)[.](?P<Job>[^.]+)[.](?P<Index>\d+)[.](?P<IP>[^.]+)[.](?P<Payload>.*)\s*$'
#timestamp_layout = "Epoch"

    [cf-collector-regex.message_fields]
    Type = "CFCollector"
    Env = "%Env%"
    Job = "%Job%"
    Index = "%Index%"
    IP = "%IP%"
    Payload = "%Payload%"

[StatsToFieldsDecoder]



[influxdb-encoder]
type = "SandboxEncoder"
filename = "lua_encoders/schema_influx.lua"

    [influxdb-encoder.config]
    series = "%{Metric}"
    skip_fields = "Pid EnvVersion Hostname Type Payload Logger Severity"
    exclude_base_fields = true


[PayloadEncoder]
append_newlines = false

[RstEncoder]

# This is useful for debugging, log everything out to stdout
#[LogOutput]
#message_matcher = 'Type =~ /heka\.*/'
#encoder = "RstEncoder"

# grab the heka process report and output to stdout
#[LogOutput]
#message_matcher = "Logger == DEA_filter || Logger == HekaProcessMessageFailures"
#encoder = "RstEncoder"

[influxdb-output]
type = "HttpOutput"
message_matcher = "Type == 'CFCollector'"
address = "http://influxdb:8086/db/cf_np/series"
username = "root"
password = "root"
encoder = "influxdb-encoder"

#[avail_mem_ratio-lt-1]
#type = "LogOutput"
#message_matcher = "Logger == 'DEA_filter'"
#message_matcher = 'Type == "CFCollector" && Fields[Job] == "DEA" && Fields[Metric] == "available_memory_ratio" && Fields[Value] < "0.88"'
#message_matcher = 'Type == "CFCollector"'
#encoder = "RstEncoder"

# sends emails alerts with simple throttling
#[DEA_available_memory_alert]
#type = "SmtpOutput"
#message_matcher = 'Type == "CFCollector" && Fields[Job] == "DEA" && Fields[Metric] == "available_memory_ratio" && Fields[Value] < "0.88"'
#send_from = "heka@monsanto.com"
#send_to = ["mjseid@monsanto.com"]
#auth = "none"
#host = "mail.monsanto.com:25"
#encoder = "AlertEncoder"
#send_interval = 300

# :Timestamp: 2015-04-24 19:27:24.496658183 +0000 UTC
# :Type: CFCollector
# :Hostname: 10.32.120.161:45926
# :Pid: 0
# :Uuid: e5e69bba-8727-4192-b98c-c55054e8a79f
# :Logger: tcp:2003
# :Payload: nats.latency.1m 1429903615714 1429903645
# :EnvVersion: 
# :Severity: 7
# :Fields:
#     | name:"Env" type:string value:"cf-np"
#     | name:"Job" type:string value:"collector"
#     | name:"Index" type:string value:"0"
#     | name:"IP" type:string value:"nil"
#     | name:"nats.latency.1m" type:double value:1.429903615714e+12
#     | name:"timestamp" type:integer value:1429903645

[DEA_filter]
type = "SandboxFilter"
#message_matcher = 'Type == "CFCollector" && Fields[Job] == "DEA" && Fields[Metric] == "available_memory_ratio" && Fields[Value] < "0.88"'
message_matcher = 'Type == "CFCollector" && Fields[Job] == "DEA" && Fields[available_memory_ratio] < 0.20'
filename = "lua_filters/dea.lua"
can_exit = true
#can_exit = false
preserve_data = false

[CFHealth_filter]
type = "SandboxFilter"
message_matcher = 'Type == "CFCollector" && Fields[healthy] != 1.0'
filename = "lua_filters/jobhealth.lua"
can_exit = true
preserve_data = false

[AlertEncoder]
type = "SandboxEncoder"
filename = "lua_encoders/alert.lua"

[SlackEncoder]
type = "SandboxEncoder"
filename = "lua_encoders/slack.lua"

  [SlackEncoder.config]
  username = "heka-bot"
#  channel = "#cloudfoundry"
  channel = "#hekatesting"

[LogOutput]
message_matcher = 'Logger == "DEA_filter" || Logger == "CFHealth_filter"' 
encoder = "AlertEncoder"

[LogOutput2]
type = "LogOutput"
#message_matcher = 'Type == "CFCollector" && Fields[Metric] == "healthy" && Fields[Value] != 1.0'
message_matcher = 'Type == "CFCollector" && (Fields[healthy] != 1.0 || (Fields[Job] == "DEA" && Fields[available_memory_ratio] < 0.20))'
encoder = "RstEncoder"


#[SlackOutput]
#type = "HttpOutput"
#message_matcher = "Logger == 'DEA_filter'" 
#address = "https://hooks.slack.com/services/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"
#encoder = "SlackEncoder"

# works but sends every match directly to slack (no throttling, etc).
#[SlackOutput]
#type = "HttpOutput"
#message_matcher = 'Type == "CFCollector" && Fields[Job] == "DEA" && Fields[Metric] == "available_memory_ratio" && Fields[Value] < "0.88"'
#address = "https://hooks.slack.com/services/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"
#encoder = "SlackEncoder"

# use this to grab lua failures
#[HekaProcessMessageFailures]
#type = "SandboxFilter"
#filename = "lua_filters/heka_process_message_failures.lua"
#ticker_interval = 60
#preserve_data = false # the counts are reset on Heka restarts and the monitoring should be too.
#message_matcher = "Type == 'heka.all-report'"



[hekad]
base_dir = "/var/cache/hekad"
