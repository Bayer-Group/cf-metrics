# Enable Heka dashboard for internal metrics and time series graphs
[Dashboard]
type = "DashboardOutput"
address = ":4352"
ticker_interval = 15

# listen on port 2003 for graphite format data coming from cloudfoundry
[tcp:2003]
type = "TcpInput"
splitter = "TokenSplitter"
decoder = "cf-collector-graphite-decoder"
address = ":2003"

[cf-collector-graphite-decoder]
type = "MultiDecoder"
subs = ['cf-collector-regex', 'StatsToFieldsDecoder']
cascade_strategy = "all"
log_sub_errors = true

[cf-collector-regex]
type = "PayloadRegexDecoder"
#  nifty go regex tester https://regoio.herokuapp.com/
# cf-np.DEA.0.10-1-2-3.available_memory_ratio 1.0 1428091803
#match_regex = '^(?P<Env>[^.]+)[.](?P<Job>[^.]+)[.](?P<Index>\d+)[.](?P<IP>[^.]+)[.](?P<Metric>\S+) (?P<Value>\S+) (?P<Timestamp>\d+)\s*$'
match_regex = '^(?P<Env>[^.]+)[.](?P<Job>[^.]+)[.](?P<Index>\d+)[.](?P<IP>[^.]+)[.](?P<Payload>(?P<Metric>\S+) .*)\s*$'
timestamp_layout = "Epoch"

    [cf-collector-regex.message_fields]
    Type = "CFCollector"
    Env = "%Env%"
    Job = "%Job%"
    Index = "%Index%"
    IP = "%IP%"
    Payload = "%Payload%"
    Metric = "%Metric%"

# send data to influxdb for persistence
[influxdb-encoder-np]
type = "SandboxEncoder"
filename = "lua_encoders/schema_influx_write.lua"

    [influxdb-encoder-np.config]
    skip_fields = "**all_base** Env IP Index Job Metric"
    database = "cf_np"
    name_prefix = "**none**"
    tag_fields = "Job Index IP"
    timestamp_precision= "s"

[influxdb-output-np]
type = "HttpOutput"
# take out a bunch of metrics we don't care about...this took it from ~500 series to ~130
message_matcher = "Type == 'CFCollector' &&  Fields[Env] == 'cf-np' && Fields[Metric] !~ /etcd.*|DopplerServer.*|LoggregatorTrafficcontroller.*|MetronAgent.*|.*timestamp.*/"
address = "http://influxdb:8086/write"
username = "root"
password = "root"
encoder = "influxdb-encoder-np"

# send data to influxdb for persistence
[influxdb-encoder-prd]
type = "SandboxEncoder"
filename = "lua_encoders/schema_influx_write.lua"

    [influxdb-encoder-prd.config]
    skip_fields = "**all_base** Env IP Index Job Metric"
    database = "cf_prd"
    name_prefix = "**none**"
    tag_fields = "Job Index IP"
    timestamp_precision= "s"

[influxdb-output-prd]
type = "HttpOutput"
# take out a bunch of metrics we don't care about...this took it from ~500 series to ~130
message_matcher = "Type == 'CFCollector' &&  Fields[Env] == 'cf-prd' && Fields[Metric] !~ /etcd.*|DopplerServer.*|LoggregatorTrafficcontroller.*|MetronAgent.*|.*timestamp.*/"
address = "http://influxdb:8086/write"
username = "root"
password = "root"
encoder = "influxdb-encoder-prd"

[PayloadEncoder]
append_newlines = false

[RstEncoder]

[StatsToFieldsDecoder]


# :Timestamp: 2015-04-24 19:27:24.496658183 +0000 UTC
# :Type: CFCollector
# :Hostname: 10.32.120.161:45926
# :Pid: 0
# :Uuid: e5e69bba-8727-4192-b98c-c55054e8a79f
# :Logger: tcp:2003
# :Payload: nats.latency.1m 1429903615714 1429903645
# :EnvVersion: 
# :Severity: 7
# :Fields:
#     | name:"Env" type:string value:"cf-np"
#     | name:"Job" type:string value:"collector"
#     | name:"Index" type:string value:"0"
#     | name:"IP" type:string value:"nil"
#     | name:"nats.latency.1m" type:double value:1.429903615714e+12
#     | name:"timestamp" type:integer value:1429903645

[DEA_filter_np]
type = "SandboxFilter"
message_matcher = 'Type == "CFCollector" && Fields[Metric] == "available_memory_ratio" && Fields[Env] == "cf-np"'
filename = "lua_filters/dea_alert_np.lua"
can_exit = true
preserve_data = false
ticker_interval = 120 

[DEA_filter_prd]
type = "SandboxFilter"
message_matcher = 'Type == "CFCollector" && Fields[Metric] == "available_memory_ratio" && Fields[Env] == "cf-prd"'
filename = "lua_filters/dea_alert_prd.lua"
can_exit = true
preserve_data = false
ticker_interval = 120

[CFHealth_filter_np]
type = "SandboxFilter"
message_matcher = 'Type == "CFCollector" && Fields[healthy] != 1.0 && Fields[Env] == "cf-np"'
filename = "lua_filters/health_alert_np.lua"
can_exit = true
preserve_data = false

[CFHealth_filter_prd]
type = "SandboxFilter"
message_matcher = 'Type == "CFCollector" && Fields[healthy] != 1.0 && Fields[Env] == "cf-prd"'
filename = "lua_filters/health_alert_prd.lua"
can_exit = true
preserve_data = false

[AlertEncoder]
type = "SandboxEncoder"
filename = "lua_encoders/alert.lua"

[SlackEncoder]
type = "SandboxEncoder"
filename = "lua_encoders/slack.lua"

  [SlackEncoder.config]
  username = "heka-bot"
  channel = "#cloudfoundry-ops"
#  channel = "#hekatesting"

[LogOutput]
message_matcher = 'Logger == "DEA_filter_np" || Logger == "DEA_filter_prd" || Logger == "CFHealth_filter"' 
#encoder = "AlertEncoder"
encoder = "RstEncoder"

#[LogOutput2]
#type = "LogOutput"
#message_matcher = 'Type == "CFCollector" && (Fields[healthy] != 1.0 || (Fields[Job] == "DEA" && Fields[available_memory_ratio] < 0.50))'
#message_matcher = 'Type == "CFCollector" && (Fields[healthy] != 1.0 || (Fields[Job] == "DEA" && Fields[available_memory_ratio] < 0.20))'
#message_matcher = 'Type == "CFCollector" && Fields[Job] == "DEA" && Fields[available_memory_ratio] == 0.66'
#message_matcher = 'Type == "CFCollector" && Fields[Job] == "DEA" && Fields[Metric] == "available_memory_ratio" && Fields[IP] == "10-32-120-168"'
#encoder = "RstEncoder"

[SlackOutput]
type = "HttpOutput"
message_matcher = 'Logger == "DEA_filter_np" || Logger == "DEA_filter_prd" || Logger == "CFHealth_filter_np" || Logger == "CFHealth_filter_prd"' 
address = "https://hooks.slack.com/services/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"
encoder = "SlackEncoder"

[hekad]
base_dir = "/var/cache/hekad"
maxprocs = 4
poolsize = 200
plugin_chansize = 50

############## examples ###########
# use this to grab lua failures
#[HekaProcessMessageFailures]
#type = "SandboxFilter"
#filename = "lua_filters/heka_process_message_failures.lua"
#ticker_interval = 60
#preserve_data = false # the counts are reset on Heka restarts and the monitoring should be too.
#message_matcher = "Type == 'heka.all-report'"

# works but sends every match directly to slack (no throttling, etc).
#[SlackOutput]
#type = "HttpOutput"
#message_matcher = 'Type == "CFCollector" && Fields[Job] == "DEA" && Fields[Metric] == "available_memory_ratio" && Fields[Value] < "0.88"'
#address = "https://hooks.slack.com/services/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"
#encoder = "SlackEncoder"

# This is useful for debugging, log everything out to stdout
#[LogOutput]
#message_matcher = 'Type =~ /heka\.*/'
#encoder = "RstEncoder"

# grab the heka process report and output to stdout
#[LogOutput]
#message_matcher = "Logger == DEA_filter || Logger == HekaProcessMessageFailures"
#encoder = "RstEncoder"

# sends emails alerts with simple throttling
#[DEA_available_memory_alert]
#type = "SmtpOutput"
#message_matcher = 'Type == "CFCollector" && Fields[Job] == "DEA" && Fields[Metric] == "available_memory_ratio" && Fields[Value] < "0.88"'
#send_from = "heka@monsanto.com"
#send_to = ["mjseid@monsanto.com"]
#auth = "none"
#host = "mail.monsanto.com:25"
#encoder = "AlertEncoder"
#send_interval = 300

